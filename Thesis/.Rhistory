library(stats)
#   calculate simple returns just simple excess returns
a <- df %>% My_excess_return(., "UK_HY", "UK")
b <- df %>% My_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% My_excess_return(., "US_HY", "US")
d <- df %>% My_excess_return(., "US_DG", "US_2")
e <- df %>% My_excess_return(., "EU_HY", "EU")
f <- df %>% My_excess_return(., "EU_DG", "EU_2")
g <- df %>% My_excess_return(., "JP_HY", "JP")
h <- df %>% My_excess_return(., "JP_DG", "JP")
i <- df %>% My_excess_return(., "EM_HY", "EM")
j <- df %>% My_excess_return(., "SA_HY", "SA")
k <- df %>% My_excess_return(., "SA_DG", "SA")
l <- df %>% My_excess_return(., "W_HY", "W")
# Table to describe excess returns
# excess_return_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
#   reduce(inner_join, by='date')
a
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
df %>% My_excess_return(., "UK_HY", "UK")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
df %>% My_excess_return(., "UK_HY", "UK")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("code/EXCESSRETURN.R")
a <- df %>% My_excess_return(., "UK_HY", "UK")
a
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("code/EXCESSRETURN.R")
library(glue)
library(stats)
#   calculate simple returns just simple excess returns
a <- df %>% My_excess_return(., "UK_HY", "UK")
b <- df %>% My_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% My_excess_return(., "US_HY", "US")
d <- df %>% My_excess_return(., "US_DG", "US_2")
e <- df %>% My_excess_return(., "EU_HY", "EU")
f <- df %>% My_excess_return(., "EU_DG", "EU_2")
g <- df %>% My_excess_return(., "JP_HY", "JP")
h <- df %>% My_excess_return(., "JP_DG", "JP")
i <- df %>% My_excess_return(., "EM_HY", "EM")
j <- df %>% My_excess_return(., "SA_HY", "SA")
k <- df %>% My_excess_return(., "SA_DG", "SA")
l <- df %>% My_excess_return(., "W_HY", "W")
# Table to describe excess returns
# excess_return_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
#   reduce(inner_join, by='date')
b
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
source("code/EXCESSRETURN.R")
library(glue)
library(stats)
#   calculate simple returns just simple excess returns
a <- df %>% My_excess_return(., "UK_HY", "UK")
b <- df %>% My_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% My_excess_return(., "US_HY", "US")
d <- df %>% My_excess_return(., "US_DG", "US_2")
e <- df %>% My_excess_return(., "EU_HY", "EU")
f <- df %>% My_excess_return(., "EU_DG", "EU_2")
g <- df %>% My_excess_return(., "JP_HY", "JP")
h <- df %>% My_excess_return(., "JP_DG", "JP")
i <- df %>% My_excess_return(., "EM_HY", "EM")
j <- df %>% My_excess_return(., "SA_HY", "SA")
k <- df %>% My_excess_return(., "SA_DG", "SA")
l <- df %>% My_excess_return(., "W_HY", "W")
# Table to describe excess returns
# excess_return_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
#   reduce(inner_join, by='date')
a
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
df %>% My_excess_return(., "UK_HY", "UK")
source("code/EXCESSRETURN.R")
library(glue)
library(stats)
#   calculate simple returns just simple excess returns
a <- df %>% My_excess_return(., "UK_HY", "UK")
b <- df %>% My_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% My_excess_return(., "US_HY", "US")
d <- df %>% My_excess_return(., "US_DG", "US_2")
e <- df %>% My_excess_return(., "EU_HY", "EU")
f <- df %>% My_excess_return(., "EU_DG", "EU_2")
g <- df %>% My_excess_return(., "JP_HY", "JP")
h <- df %>% My_excess_return(., "JP_DG", "JP")
i <- df %>% My_excess_return(., "EM_HY", "EM")
j <- df %>% My_excess_return(., "SA_HY", "SA")
k <- df %>% My_excess_return(., "SA_DG", "SA")
l <- df %>% My_excess_return(., "W_HY", "W")
# Table to describe excess returns
# excess_return_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
#   reduce(inner_join, by='date')
l
des_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
des_df
t(des_df)
tibble::tibble(t(des_df))
tibble::tibble(t(des_df))
des_df<-t(des_df)
des_df
des_df<-t(des_df)
rownames(des_df) <- NULL
des_df
des_df<-t(des_df)
des_df
as.data.frame(des_df)
des_df<-t(des_df) %>% as.data.frame(.)
des_df[-1, ]
t(des_df) %>% as.data.frame(.)
des_df<-t(des_df) %>% as.Dataframe(.)
list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
des_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
t(des_df)
des_df<-t(des_df)
des_df[-1, ]
des_df<-t(des_df)
des_df
colnames(des_df) <- as.character(unlist(des_df[1,]))
des_df
des_df<-t(des_df)
des_df
colnames(des_df) <- as.character(unlist(des_df[1,]))
des_df
des_df[-1, ]
des_df[-1, ] <- as.data.frame(des_df)
des_df
des_df[-1, ] <- as.data.frame(des_df)
des_df <- des_df[-1, ]
des_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
des_df<-t(des_df)
colnames(des_df) <- as.character(unlist(des_df[1,]))
des_df <- des_df[-1, ]
des_df
des_df <- as.data.frame(des_df)
des_df
list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
if (!require("fEcofin")) install.packages("fEcofin", repos = "http://R-Forge.R-project.org")
library(fEcofin)
pacman::p_load("tidyr", "dplyr")
DJ = DowJones30
# Let's dplyr and fix this dataset:
DJ <- DJ %>% mutate(Date = as.Date(X.Y..m..d)) %>% select(-X.Y..m..d) %>%
tbl_df()
# Let's create log returns for each column:
DJ <- DJ %>% mutate_at(vars(-Date), ~log(.) - log(lag(.))) %>%
filter(Date > first(Date))
head(DJ)
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/EXCESSRETURN.R")
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue", "zoo")
df<- readxl::read_xlsx("data/MAD .xlsx")
#  change the column names for ease of analysis
geographical_codenames <- c("UK_HY", "EM_HY", "UK", "EM", "UK_HY_B", "UK_B", "JP_HY", "EU", "US_HY", "US", "W_HY", "W", "EU_DG", "EU_2", "JP_DG", "US_DG", "US_2", "JP", "SA_DG", "SA", "SA_HY", "EU_HY", "W_HY", "W")
colnames(df)[2:23] <- geographical_codenames
df
df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.)))
violinBy(DJ %>% select(-Date) %>% as.matrix())
# loadings
if (!require("fEcofin")) install.packages("fEcofin", repos = "http://R-Forge.R-project.org")
library(fEcofin)
library(PerformanceAnalytics)
pacman::p_load("tidyr", "dplyr")
df<- readxl::read_xlsx("data/MAD .xlsx")
#  change the column names for ease of analysis
geographical_codenames <- c("UK_HY", "EM_HY", "UK", "EM", "UK_HY_B", "UK_B", "JP_HY", "EU", "US_HY", "US", "W_HY", "W", "EU_DG", "EU_2", "JP_DG", "US_DG", "US_2", "JP", "SA_DG", "SA", "SA_HY", "EU_HY", "W_HY", "W")
colnames(df)[2:23] <- geographical_codenames
#  the series of returns not excess returns, does this change affect the interpreation
df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.)))
# lets check the ditribution for each portfolio
violinBy(DJ %>% select(-Date) %>% as.matrix())
fact_df <- df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.)))
#  the series of returns not excess returns, does this change affect the interpreation
fact_df <- df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.)))
# lets check the ditribution for each portfolio
violinBy(fact_df %>% select(-Date) %>% as.matrix())
?violinBy
??violinBy
p_load("psych")
library(pacman)
p_load("psych")
library(psych)
#  the series of returns not excess returns, does this change affect the interpreation
fact_df <- df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.)))
# lets check the ditribution for each portfolio
violinBy(fact_df %>% select(-Date) %>% as.matrix())
??violinBy
pca <- princomp(fact_df %>% select(-Date), cor=F)
fact_df
source("code/impute.R")
View(impute_missing_returns)
fact_df %>% impute_missing_returns(., "Drawn_Distribution_Collective" )
fact_df <- df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>% rename(date = Date)
fact_df %>% impute_missing_returns(., "Drawn_Distribution_Collective" )
fact_df %>% impute_missing_returns(., "Drawn_Distribution_Collective" )
fact_df <- fact_df %>% impute_missing_returns(., "Drawn_Distribution_Collective" )
pca <- princomp(fact_df %>% select(-Date), cor=F)
pca <- princomp(fact_df %>% select(-date), cor=F)
plot(pca)
pca <- princomp(fact_df %>% select(-date), cor=F)
plot(pca, type = "l")
d.fa <- factanal(fact_df %>% select(-date), factors = 1, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 2, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 4, rotation = "varimax")
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 3, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 1, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 2, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
source("code/EXCESSRETURN.R")
library(glue)
library(stats)
#   calculate simple returns just simple excess returns
a <- df %>% My_excess_return(., "UK_HY", "UK")
b <- df %>% My_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% My_excess_return(., "US_HY", "US")
d <- df %>% My_excess_return(., "US_DG", "US_2")
e <- df %>% My_excess_return(., "EU_HY", "EU")
f <- df %>% My_excess_return(., "EU_DG", "EU_2")
g <- df %>% My_excess_return(., "JP_HY", "JP")
h <- df %>% My_excess_return(., "JP_DG", "JP")
i <- df %>% My_excess_return(., "EM_HY", "EM")
j <- df %>% My_excess_return(., "SA_HY", "SA")
k <- df %>% My_excess_return(., "SA_DG", "SA")
l <- df %>% My_excess_return(., "W_HY", "W")
#  some high level descriptive stats
des_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
# this is the pre ample to the overall portfolio nalaysis that I will be conducting
des_df
df %>% mutate_at(vars(-Date), ~log(.)-lag(log(.)))
df
# loadings
if (!require("fEcofin")) install.packages("fEcofin", repos = "http://R-Forge.R-project.org")
library(fEcofin)
library(PerformanceAnalytics)
pacman::p_load("tidyr", "dplyr")
df<- readxl::read_xlsx("data/MAD .xlsx")
#  change the column names for ease of analysis
geographical_codenames <- c("UK_HY", "EM_HY", "UK", "EM", "UK_HY_B", "UK_B", "JP_HY", "EU", "US_HY", "US", "W_HY", "W", "EU_DG", "EU_2", "JP_DG", "US_DG", "US_2", "JP", "SA_DG", "SA", "SA_HY", "EU_HY", "W_HY", "W")
colnames(df)[2:23] <- geographical_codenames
df %>% mutate_at(vars(-Date), ~log(.)-lag(log(.)))
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.)))
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% tbl_xts()
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
library(psych)
source("code/impute.R")
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% rename(date = Date)
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% rename(date = Date) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% rename(date = Date) %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
fact_df <- df %>% arrange(Date) %>%  mutate_at(vars(-Date), ~log(.)-lag(log(.))) %>% rename(date = Date) %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
View(fact_df)
?grepl
df %>% rename(index = Index_Name, bm = Benchmark_Name, date = Date) %>% gather(vars, px, -date) %>%  grepl(c("index", "bm" ), vars) %>% arrange(Date) %>% spread_by(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
df %>% rename(index = Index_Name, bm = Benchmark_Name, date = Date) %>% gather(vars, px, -date) %>%  grepl(c("index", "bm" ), vars) %>% arrange(Date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>%  grepl(c("index", "bm" ), vars) %>% arrange(Date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
df %>% rename(index = "UK_HY", bm = "UK", date = Date)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>%  grepl(c("index", "bm" ), vars)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>%  grepl(("index", "bm" ), vars)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm"))
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% tbl_xts()
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective")
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% mutate(exret = index - bm)
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% mutate(exret = index - bm, YM = format(date, "%Y %b")) %>% group_by(YM) %>% filter(date == last(date))
df %>% rename(index = "UK_HY", bm = "UK", date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% mutate(exret = index - bm, YM = format(date, "%Y %b")) %>% group_by(YM) %>% filter(date == last(date)) %>% select(date, exret)
df %>% rename(index = Index, bm = BM, date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% mutate(exret = index - bm, YM = format(date, "%Y %b"), `Index Name` = !!glue("{Index}")) %>% group_by(YM) %>% filter(date == last(date)) %>% select(date, exret, Name) %>% ungroup()
monthly_excess_return <- function(df, Index, BM, impute = "Drawn_Distribution_Collective" ){
source("code/impute.R")
fact_df <- df %>% rename(index = Index, bm = BM, date = Date) %>% gather(vars, px, -date) %>% filter( vars %in% c("index", "bm")) %>% arrange(date) %>% spread(vars, px)  %>% mutate_at(vars(-date), ~log(.)-lag(log(.)))  %>% impute_missing_returns(., "Drawn_Distribution_Collective") %>% mutate(exret = index - bm, YM = format(date, "%Y %b"), `Index Name` = Index ) %>% group_by(YM) %>% filter(date == last(date)) %>% select(date, exret, Name) %>% ungroup()}
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
#  the series of returns not excess returns, does this change affect the interpreation, just returns leaves a lot to wonder, can collapse the information set to just a few variables
source("code/Factor_model_return.R")
monthly_excess_return(df, "UK_HY", "UK")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("code/Factor_model_return.R")
monthly_excess_return(df, "UK_HY", "UK")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
monthly_excess_return(df, "UK_HY", "UK")
source("code/Factor_model_return.R")
monthly_excess_return(df, "UK_HY", "UK")
a <- monthly_excess_return(df, "UK_HY", "UK")
View(a)
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("code/Factor_model_return.R")
a <- monthly_excess_return(df, "UK_HY", "UK")
View(a)
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("code/Factor_model_return.R")
a <- monthly_excess_return(df, "UK_HY", "UK")
View(a)
library(psych)
#  the series of returns not excess returns, does this change affect the interpreation, just returns leaves a lot to wonder, can collapse the information set to just a few variables
source("code/Factor_model_return.R")
a <- df %>% monthly_excess_return(., "UK_HY", "UK")
b <- df %>% monthly_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% monthly_excess_return(., "US_HY", "US")
d <- df %>% monthly_excess_return(., "US_DG", "US_2")
e <- df %>% monthly_excess_return(., "EU_HY", "EU")
f <- df %>% monthly_excess_return(., "EU_DG", "EU_2")
g <- df %>% monthly_excess_return(., "JP_HY", "JP")
h <- df %>% monthly_excess_return(., "JP_DG", "JP")
i <- df %>% monthly_excess_return(., "EM_HY", "EM")
j <- df %>% monthly_excess_return(., "SA_HY", "SA")
k <- df %>% monthly_excess_return(., "SA_DG", "SA")
l <- df %>% monthly_excess_return(., "W_HY", "W")
#  some high level descriptive stats
fact_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='Measure')
a
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
source("code/Factor_model_return.R")
df %>% monthly_excess_return(., "UK_HY", "UK")
source("~/Desktop/Much Ado Dividends/Much-Ado-Dividends/Thesis/code/Factor_model_return.R")
df %>% monthly_excess_return(., "UK_HY", "UK")
df %>% monthly_excess_return(., "UK_HY", "UK")
source("code/Factor_model_return.R")
df %>% monthly_excess_return(., "UK_HY", "UK")
a <- df %>% monthly_excess_return(., "UK_HY", "UK")
View(a)
library(psych)
#  the series of returns not excess returns, does this change affect the interpreation, just returns leaves a lot to wonder, can collapse the information set to just a few variables
source("code/Factor_model_return.R")
a <- df %>% monthly_excess_return(., "UK_HY", "UK")
b <- df %>% monthly_excess_return(., "UK_HY_B", "UK_B")
c <- df %>% monthly_excess_return(., "US_HY", "US")
d <- df %>% monthly_excess_return(., "US_DG", "US_2")
e <- df %>% monthly_excess_return(., "EU_HY", "EU")
f <- df %>% monthly_excess_return(., "EU_DG", "EU_2")
g <- df %>% monthly_excess_return(., "JP_HY", "JP")
h <- df %>% monthly_excess_return(., "JP_DG", "JP")
i <- df %>% monthly_excess_return(., "EM_HY", "EM")
j <- df %>% monthly_excess_return(., "SA_HY", "SA")
k <- df %>% monthly_excess_return(., "SA_DG", "SA")
l <- df %>% monthly_excess_return(., "W_HY", "W")
#  some high level descriptive stats
fact_df <- list( a, b, c, d, e,f,g,h,i,j,k, l) %>%
reduce(inner_join, by='date')
# fact_df <- df %>% arrange(Date) %>% mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>% rename(date = Date)
# fill the missiing returns by a distribution of others, in the analysis mention that all variables now have some level of return
# lets check the ditribution for each portfolio
violinBy(fact_df %>% select(-Date) %>% as.matrix())
fact_df
violinBy(fact_df %>% select(-date) %>% as.matrix())
pca <- princomp(fact_df %>% select(-date), cor=F)
plot(pca)
pca <- princomp(fact_df %>% select(-date), cor=F)
plot(pca, type = "l")
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 1, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 2, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 3, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 4, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 2, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
df %>% arrange(Date) %>%
mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>%
rename(date = Date) %>% gather(index, ret) %>% filter(index %in% c("_HY", "_DG"))
df %>% arrange(Date) %>%
mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>%
rename(date = Date) %>% gather(index, ret) %>% filter(index %in% c("HY", "DG"))
View(df)
df %>% arrange(Date) %>%
mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>%
rename(date = Date) %>% gather(index, ret) %>% filter(index %in% grepl(("HY"|"DG"), index))
df %>% arrange(Date) %>%
mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>%
rename(date = Date) %>% gather(index, ret) %>% filter(grepl(("HY"|"DG"), index))
df %>% arrange(Date) %>%
mutate_at(vars(-Date), ~log(.)- lag(log(.))) %>%
rename(date = Date) %>% gather(index, ret) %>% filter(grepl("HY"|"DG", index))
df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret) %>%
filter(grepl("HY|DG", index))
df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret,-date) %>%
filter(grepl("HY|DG", index))
df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret,-date) %>%
filter(grepl("HY|DG", index)) %>% spread(index, ret)
source("code/impute.R")
View(impute_missing_returns)
df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret,-date) %>%
filter(grepl("HY|DG", index)) %>% spread(index, ret) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
fact_df <- df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret,-date) %>%
filter(grepl("HY|DG", index)) %>% spread(index, ret) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
library(psych)
source("code/impute.R")
#  the series of returns not excess returns, does this change affect the interpreation, just returns leaves a lot to wonder, can collapse the information set to just a few variables
# source("code/Factor_model_return.R")
#
# a <- df %>% monthly_excess_return(., "UK_HY", "UK")
# b <- df %>% monthly_excess_return(., "UK_HY_B", "UK_B")
# c <- df %>% monthly_excess_return(., "US_HY", "US")
# d <- df %>% monthly_excess_return(., "US_DG", "US_2")
#
# e <- df %>% monthly_excess_return(., "EU_HY", "EU")
# f <- df %>% monthly_excess_return(., "EU_DG", "EU_2")
# g <- df %>% monthly_excess_return(., "JP_HY", "JP")
# h <- df %>% monthly_excess_return(., "JP_DG", "JP")
#
# i <- df %>% monthly_excess_return(., "EM_HY", "EM")
# j <- df %>% monthly_excess_return(., "SA_HY", "SA")
# k <- df %>% monthly_excess_return(., "SA_DG", "SA")
# l <- df %>% monthly_excess_return(., "W_HY", "W")
#  some high level descriptive stats
fact_df <- df %>%
arrange(Date) %>%
mutate_at(vars(-Date), ~log(.) - lag(log(.))) %>%
rename(date = Date) %>%
gather(index, ret,-date) %>%
filter(grepl("HY|DG", index)) %>% spread(index, ret) %>% impute_missing_returns(., "Drawn_Distribution_Collective")
# fill the missiing returns by a distribution of others, in the analysis mention that all variables now have some level of return
# lets check the ditribution for each portfolio
violinBy(fact_df %>% select(-date) %>% as.matrix())
# lets get an idea of how many factors to include. It says one but lets take it to town and say 4, there seems to be anaother drop off in returns
pca <- princomp(fact_df %>% select(-date), cor=F)
plot(pca, type = "l")
#
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 1, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 2, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
# lets test the model fit for all the factor model
d.fa <- factanal(fact_df %>% select(-date), factors = 3, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
# using a moodel with just the first factor gives the best model, as indicated by the CHI square measure
d.fa$loadings
d.fa %>% as.tibble()
d.fa$loadings %>% as.tibble()
d.fa <- factanal(fact_df %>% select(-date), factors = 1, rotation = "varimax")
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
d.fa$loadings %>% as.tibble()
d.fa$loadings %>% as.tibble()
first_loadings <- d.fa$loadings %>% as.tibble()
View(first_loadings)
first_loadings
View(first_loadings)
View(h)
d.fa$loadings %>% as.tibble()
d.fa$loadings %>% as.tibble()
View(first_loadings)
print(d.fa, digits = 2, cutoff = 0.2, sort = TRUE)
d.fa$uniquenesses
tibble(d.fa$uniquenesses)
consistency_df %>% select(IR) %>% pull()
consistency_df %>% select(IR) %>% pull()
library(tidyverse)
consistency_df %>% select(IR) %>% pull()
consistency_df %>% select(IR) %>% pull %>% as.vector()
consistency_df %>% select(IR) %>% pull %>% as.vector() %>% distinct()
consistency_df %>% select(IR) %>%distinct() %>%  pull %>% as.vector()
