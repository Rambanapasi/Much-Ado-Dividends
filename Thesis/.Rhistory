mutate(Ret = Price / lag(Price)) %>%
# this should be a variable
filter(Date %in% filter_vector) %>%
#  get a vector of all indices
mutate(Year = format(Date, "%y")) %>%
group_by(Index) %>%
mutate(Count = n()) %>%
summarise(Excess_Return = prod(1+ Ret, na.rm=T) ^ (12/(Count)) -1 )
df}
df %>% regime_return(., sa_rate_high_vol)
sa_rate_high_vol
#  now lets get its return, use the same df from the other vol stratification
df
#  now lets get its return, use the same df from the other vol stratification
combined_simple
vol_date_vector <- rateschanges %>%
regime_date_extractor(. , Regime = "Hiking", Bank = "Fed") %>% as.Date() %>% unique()
combined_simple
combined_simple %>%
filter(date %in% vol_date_vector) %>%
group_by(date, ticker) %>%
mutate(Periodicy = n()) %>%
# lets annulize accroding to periodicity
summarise(Annualized_Return = prod(1+excess, na.rm=T) ^ (12/(Periodicy)) -1 ) %>%
ungroup
combined_simple %>% arrange(date)
combined_simple %>% arrange(date) %>%
filter(date %in% vol_date_vector)
vol_date_vector <- rateschanges %>%
regime_date_extractor(. , Regime = "Hiking", Bank = "Fed") %>% as.Date() %>% unique()
combined_simple %>% arrange(date) %>%
filter(date %in% vol_date_vector)
vol_date_vector
combined_simple %>% arrange(date)
combined_simple %>% arrange(date) %>%
filter( vol_date_vector %in% date)
combined_simple %>% arrange(date) %>%
filter(date %in% vol_date_vector)
rateschanges %>%
regime_date_extractor(. , Regime = "Hiking", Bank = "Fed") %>% as.Date() %>% unique()
rateschanges %>%
regime_date_extractor(. , Regime = "Cutting", Bank = "Fed") %>% as.Date() %>% unique()
View(regime_date_extractor)
divi_vol_df
View(regime_date_extractor)
excessreturns_us
rateschanges
interest
View(market_cycle_df)
?sum
quarters <- c("Mar", "Jun", "Sep", "Dec")
#  With that subset of interest rates now use if else and group by date to count times when there was a hiking or cutting
rateschanges <- tidy_interest %>%
group_by (YM, Bank) %>%
filter(Date == last(Date)) %>%
filter(Month %in% quarters) %>%
arrange(Date) %>%
group_by(Bank) %>%
mutate(diff = Rate - lag(Rate)) %>%
mutate(Year = format(Date, "%Y")) %>%
group_by(Year) %>%
mutate(
Changes = case_when(
count(diff > 0, na.rm = TRUE) > 4 ~ "Hiking",
count(diff < 0, na.rm = TRUE) > 4 ~ "Cutting",
TRUE ~ "Hold"
)
interest <- interest %>%
interest <- interest %>%
gather(Bank, Rate, -Date) %>%
mutate( Month = format(Date, "%b"), YM = format(Date, "%b %y")) %>%
arrange(Date) %>%
group_by(Bank) %>%
ungroup()
#  subset dates to just consider the quarterly figures
quarters <- c("Mar", "Jun", "Sep", "Dec")
#  With that subset of interest rates now use if else and group by date to count times when there was a hiking or cutting
rateschanges <- tidy_interest %>%
group_by (YM, Bank) %>%
filter(Date == last(Date)) %>%
filter(Month %in% quarters) %>%
arrange(Date) %>%
group_by(Bank) %>%
mutate(diff = Rate - lag(Rate)) %>%
mutate(Year = format(Date, "%Y")) %>%
group_by(Year) %>%
mutate(
Changes = case_when(
count(diff > 0, na.rm = TRUE) > 4 ~ "Hiking",
count(diff < 0, na.rm = TRUE) > 4 ~ "Cutting",
TRUE ~ "Hold"
)
) %>%
ungroup()
tidy_interest %>%
group_by (YM, Bank) %>%
filter(Date == last(Date)) %>%
filter(Month %in% quarters) %>%
arrange(Date) %>%
group_by(Bank) %>%
mutate(diff = Rate - lag(Rate)) %>%
mutate(Year = format(Date, "%Y")) %>%
group_by(Year) %>%
mutate(
Changes = case_when(
count(diff > 0) > 4 ~ "Hiking",
count(diff < 0) > 4 ~ "Cutting",
TRUE ~ "Hold"
)
)
tidy_interest %>%
group_by (YM, Bank) %>%
filter(Date == last(Date)) %>%
filter(Month %in% quarters) %>%
arrange(Date) %>%
group_by(Bank) %>%
mutate(diff = Rate - lag(Rate)) %>%
mutate(Year = format(Date, "%Y")) %>%
group_by(Year) %>%
mutate(
Changes = case_when(
sum(diff > 0) > 4 ~ "Hiking",
sum(diff < 0) > 4 ~ "Cutting",
TRUE ~ "Hold"
)
)
tidy_interest %>%
group_by (YM, Bank) %>%
filter(Date == last(Date)) %>%
filter(Month %in% quarters) %>%
arrange(Date) %>%
group_by(Bank) %>%
mutate(diff = Rate - lag(Rate)) %>%
mutate(Year = format(Date, "%Y")) %>%
group_by(Year) %>%
mutate(
Changes = case_when(
sum(diff > 0) > 3 ~ "Hiking",
sum(diff < 0) > 3 ~ "Cutting",
TRUE ~ "Hold"
)
) %>%
ungroup()
rateschanges
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!
# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(gt)
library(tidyverse)
library(huxtable)
library(kableExtra)
pacman::p_load("TTR")
pacman::p_load("tidyr", "tbl2xts","devtools","lubridate", "readr", "PerformanceAnalytics", "ggplot2", "dplyr")
data <- readxl::read_xlsx("data/MAD .xlsx")
# Notice that as you are working in a .Rproj file (I am assuming you are) - the relative paths of your directories start at your specified root.
# This means that when working in a .Rproj file, you never need to use getwd() - it is assumed as your base root automatically.
divi_vol_df
vol_data <- readxl::read_xlsx("data/volatility.xlsx")
VIX <- vol_data %>% select(Date, VIX)
V2X <- vol_data %>% select(Date, V2X)
JSV <- vol_data %>% select(Date, JALSHVOL)
# get rolling sd for the volatility index
source("code/rollingstarnddev.R")
# US
Vixroll <- Rolling_sd(VIX ,"VIX")
# get the top quartile and bottom quartil
strat_df <- Vixroll %>% mutate(topQ = quantile(RollSD, probs = 0.8),
botQ = quantile(RollSD, probs = 0.2),
Strat = ifelse(RollSD >= topQ, "HiVol",
ifelse(RollSD <= botQ, "LowVol", "Normal_Vol")))
# US strat
hivol_per_vector_us <- strat_df %>% filter(Strat %in% "HiVol") %>% pull(Date)
lovol_per_vector_us <- strat_df %>% filter(Strat %in% "LowVol") %>% pull(Date)
# Europe strat
Vixroll <- Rolling_sd(V2X ,"V2X")
# get the top quartile and bottom quartil
strat_df <- Vixroll %>% mutate(topQ = quantile(RollSD, probs = 0.8),
botQ = quantile(RollSD, probs = 0.2),
Strat = ifelse(RollSD >= topQ, "HiVol",
ifelse(RollSD <= botQ, "LowVol", "Normal_Vol")))
hivol_per_vector_eu  <- strat_df %>% filter(Strat %in% "HiVol") %>% pull(Date)
lovol_per_vector_eu  <- strat_df %>% filter(Strat %in% "LowVol") %>% pull(Date)
# SA
Vixroll <- Rolling_sd(JSV ,"JALSHVOL")
# get the top quartile and bottom quartil
strat_df <- Vixroll %>% mutate(topQ = quantile(RollSD, probs = 0.8),
botQ = quantile(RollSD, probs = 0.2),
Strat = ifelse(RollSD >= topQ, "HiVol",
ifelse(RollSD <= botQ, "LowVol", "Normal_Vol")))
hivol_per_vector_sa <- strat_df %>% filter(Strat %in% "HiVol") %>% pull(Date)
lovol_per_vector_sa <- strat_df %>% filter(Strat %in% "LowVol") %>% pull(Date)
# get entire returns and apply the vector above
# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# get all permutatation
A <- df %>% simple_excess_return(.,"FUDP", "TUKXG")
B <- df %>% simple_excess_return(., "M2EFDY", "GDUEEGF")
C <- df %>% simple_excess_return(., "M2EUGDY", "GDDUE15X")
D <- df %>% simple_excess_return(., "M2GBDY", "GDDUUK")
E <- df %>% simple_excess_return(., "M2JPDY", "TJDIVD")
F1 <- df %>% simple_excess_return(., "M2USADVD", "GDDUUS")
G <- df %>% simple_excess_return(., "M2WDHDVD", "GDDUWI")
H <- df %>% simple_excess_return(., "SPDAEET", "SPTR350E")
I <- df %>% simple_excess_return(., "SPDAUDT", "SPXT")
J <- df %>% simple_excess_return(., "SPJXDAJT", "TPXDDVD")
K <- df %>% simple_excess_return(., "SPSADAZT", "JALSH")
L <- df %>% simple_excess_return(., "TJDIVD", "JALSH")
combined_simple<- list(A, B, C, D, E, F1, G,H,J, K, L) %>%
reduce(inner_join, by='date') %>% gather(ticker, excess, -date)
#  US excess return
excessreturns_us <- list( F1, I ,J) %>%
reduce(inner_join, by='date') %>% gather(ticker, excess, -date)
# EU  excess return
excessreturns_eu <- list(A, C, D, H) %>%
reduce(inner_join, by='date') %>% gather(ticker, excess, -date)
#  SA excess returns in a single data frame
excessreturns_em <- list(B, K, L) %>%
reduce(inner_join, by='date') %>% gather(ticker, excess, -date)
# US stat df
hivol <- excessreturns_us %>%
filter(date %in% hivol_per_vector_us) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(Hivol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
lovol <-  excessreturns_us %>%
filter(date %in% lovol_per_vector_us) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(lovol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
Usvolcom <- left_join(hivol, lovol, by = "ticker")
# EU strat df
hivol <- excessreturns_eu %>%
filter(date %in% hivol_per_vector_eu) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(Hivol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
lovol <-  excessreturns_eu %>%
filter(date %in% lovol_per_vector_eu) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(lovol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
euvolcom <- left_join(hivol, lovol, by = "ticker")
# EM strat df
hivol <- excessreturns_em %>%
filter(date %in% hivol_per_vector_sa) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(Hivol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
lovol <-  excessreturns_em %>%
filter(date %in% lovol_per_vector_sa) %>%
filter(date >= fmxdat::safe_month_min(last(date), N = 36)) %>%
group_by(ticker) %>%
summarise(lovol_return = prod(1+excess, na.rm=T) ^ (12/(36)) -1 )
emvolcom <- left_join(hivol, lovol, by = "ticker")
divi_vol_df <- bind_rows(Usvolcom, euvolcom, emvolcom)
divi_vol_df  <- divi_vol_df %>%
mutate(Volatility_Protection = case_when(
Hivol_return > lovol_return ~ "higher",
TRUE ~ "lower"
))
divi_vol_df
table <- xtable(divi_vol_df, caption = "previous studies \\label{tab1}")
library(xtable)
xtable(divi_vol_df, caption = "previous studies \\label{tab1}")
print.xtable(table,
tabular.environment = "longtable",
floating = TRUE,
table.placement = 'H',
# scalebox = 0.3,
comment = FALSE,
caption.placement = 'bottom'
)
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
root_df <- readxl::read_xlsx("data/MAD .xlsx")
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
root_df <- readxl::read_xlsx("data/MAD .xlsx")
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
root_df <- readxl::read_xlsx("data/MAD .xlsx")
benchmarks <- readxl::read_xlsx("data/benchmarks.xlsx")
indexes <- readxl::read_xlsx("data/indices.xlsx")
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
benchmarks <- readxl::read_xlsx("data/benchmarks.xlsx")
indexes <- readxl::read_xlsx("data/indices.xlsx")
#  clean and code the names and the indices accordingly
benchmarks
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
benchmarks <- readxl::read_xlsx("data/benchmarks.xlsx")
indexes <- readxl::read_xlsx("data/indices.xlsx")
#  clean and code the names and the indices accordingly
benchmarks
benchmarks %>% gsub(" Index", "")
benchmarks %>% gsub(" Index", "", colnames(benchmarks))
benchmarks %>% gsub("\nIndex", "", colnames(benchmarks))
benchmarks %>% gsub("\\Index", "", colnames(benchmarks))
colnames(benchmarks) <- gsub("\\\\Index", "", colnames(benchmarks))
benchmarks
colnames(benchmarks) <- gsub("\\\\Index", "", colnames(benchmarks))
benchmarks
colnames(benchmarks) <- gsub(" INDEX", "", colnames(benchmarks))
benchmarks
benchmarks
colnames(benchmarks) <- gsub(" Index", "", colnames(benchmarks))
colnames(benchmarks) <- gsub(" Index", "", colnames(benchmarks))
benchmarks
indexes
indexes %>% colnames()
codename <- c("UK_HY", "EM_HY", "EU_HY", "UK_HY", "JP_HY", "US_HY", "EU_DG", "US_DG", "SA_DG", "SA_HY")
indexes %>%
purrr::set_names(colnames(.), codename))
indexes
indexes %>%
purrr::set_names(2:12, codename)
codename <- c("UK_HY", "EM_HY", "EU_HY", "UK_HY", "JP_HY", "US_HY", "EU_DG", "US_DG", "SA_DG", "SA_HY")
indexes %>%
purrr::set_names(2:12, codename)
indexes
indexes %>% colnames
codename <- c("UK_HY", "EM_HY", "EU_HY", "UK_HY", "JP_HY", "US_HY", "EU_DG", "US_DG", "JP_DG", "SA_DG", "SA_HY")
indexes %>%
purrr::set_names(2:12, codename)
indexes %>%
purrr::set_names(3:12, codename)
indexes %>%
purrr::set_names(1:12, codename)
indexes %>%
purrr::set_names(2:12, codename)
colnames(indexes)[2:12] <- codenames
colnames(indexes)[2:12] <- codename
indexes
benchmarks
indexes %>% grepl("SA", colnames(.))
indexes %>% grepl("SA", 2;12)
indexes %>% grepl("SA", 2;12)
indexes %>% grepl("SA", 2:12)
indexes %>% grepl(" SA", 2:12)
indexes %>% grepl("", .(2:12))
indexes %>% grepl("", .[2:12])
indexes[grepl , colnames(indexes)]
indexes[grepl("UK", colnames(indexes)]
indexes[, grepl("UK", colnames(indexes)]
indexes[ , grepl("UK", colnames(indexes))]
indexes[ , grepl("UK|Date", colnames(indexes))]
UK_benchmark <- benchmarks[, grepl("UK", colnames (benchmarks))]
UK_df <- leftjoin(UK_Index, UK_benchmark, "Date")
UK_df <- left_join(UK_Index, UK_benchmark, "Date")
UK_Index <- indexes[ , grepl("UK|Date", colnames(indexes))]
original_df <-readxl::read.xlsx("data/MAD .xlsx")
original_df <-read.xlsx("data/MAD .xlsx")
original_df <- readxl::read_xlsx("data/MAD .xlsx")
orginal_df %>% colnames()
orginal_df %>% colnames
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
original_df <- readxl::read_xlsx("data/MAD .xlsx")
orginal_df %>% colnames
original_df %>% colnames
geographical_codenames <- c("UK_HY", "EM_HY", "UK", "EM", "UK_HY_B", "UK_B", "JP_HY", "EU", "US_HY", "US", "W_HY", "W", "EU_DG", "EU_2", "JP_DG", "US_DG", "US_2", "JP", "SA_DG", "SA", "SA_HY", "EU_HY")
original_df
colnames(original_df)[2:23] <- geographical_codenames
original_df
UK_df <- original_df %>% .[, grepl("UK|Date", colnames(.)) ]
UK_df
UK_df <- original_df %>% .[, grepl("UK|Date", colnames(.)) ]
US_df <- original_df %>% .[, grepl("US|Date", colnames(.)) ]
EU_df <- original_df %>% .[, grepl("EU|Date", colnames(.)) ]
EM_df <- original_df %>% .[, grepl("EM|Date", colnames(.)) ]
JP_df <- original_df %>% .[, grepl("JP|Date", colnames(.)) ]
SA_df <- original_df %>% .[, grepl("SA|Date", colnames(.)) ]
SA_df
source("code/simpleexcessreturn.R")
View(simple_excess_return)
UK_df %>% mutate_at(Excess_return_HY = simple_excess_return(., "UK_HY", "UK"), Excess_return_DG = simple_excess_return(., "UK_DG", "UK_2")
UK_df %>% mutate_at(Excess_return_HY = simple_excess_return(., "UK_HY", "UK"), Excess_return_DG = simple_excess_return(., "UK_DG", "UK_2"))
UK_df %>% mutate_at(Excess_return_HY = simple_excess_return(., "UK_HY", "UK"))
UK_df %>% mutate(Excess_return_HY = simple_excess_return(., "UK_HY", "UK"))
UK_df %>% colnames
UK_df %>% mutate(Excess_return = simple_excess_return(., "UK_HY", "UK"))
UK_df %>% mutate(Excess_return = simple_excess_return(UK_df, "UK_HY", "UK"))
Excess_return = simple_excess_return(UK_df, "UK_HY", "UK")
View(Excess_return)
UK_df %>% colnames
UK_df %>% mutate(simple_excess_return(., "UK_HY", "UK"))
UK_df %>% mutate(simple_excess_return(., UK_HY, UK))
simple_excess_return(UK_df, "UK_HY", "UK"))
simple_excess_return(UK_df, "UK_HY", "UK")
UK_df %>% colnames
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY_B", "UK_B")
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df_2 <- simple_excess_return(UK_df, "UK_HY_B", "UK_B")
left_join(UK_HY_Df, UK_HY_Df_2, Date )
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df_2 <- simple_excess_return(UK_df, "UK_HY_B", "UK_B")
Uk <-  left_join(UK_HY_Df, UK_HY_Df_2, Date )
UK_HY_Df
Uk <-  left_join(UK_HY_Df, UK_HY_Df_2, date )
UK_HY_Df_2
Uk <-  left_join(UK_HY_Df, UK_HY_Df_2, date)
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df_2 <- simple_excess_return(UK_df, "UK_HY_B", "UK_B")
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK") %>% paste0("Exess_of_",  )
library(glue)
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK") %>% glue("Exess_of_{UK_HY}" )
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK") %>% paste0("Excess_of", 2)
View(UK_df)
UK_HY_Df
UK_HY_Df <- simple_excess_return(UK_df, "UK_HY", "UK") %>% paste0("Excess_of", 1)
UK_HY_Df
UK_HY_Df<- simple_excess_return(UK_df, "UK_HY", "UK")
View(simple_excess_return)
UK_HY_Df<- simple_excess_return(UK_df, "UK_HY", "UK") %>% purrr::set_names(paste0("Excess_of", 2))
UK_HY_Df
UK_HY_Df<- simple_excess_return(UK_df, "UK_HY", "UK") %>% purrr::set_names(Date, paste0("Excess_of"))
UK_HY_Df<- simple_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df_2 <- simple_excess_return(UK_df, "UK_HY_B", "UK_B")
Uk <-  left_join(UK_HY_Df, UK_HY_Df_2, date)
source("code/EXCESSRETURN.R")
UK_HY_Df<- MY_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df<- MY_excess_return(UK_df, "UK_HY", "UK")
UK_HY_Df_2 <- My_excess_return(UK_df, "UK_HY_B", "UK_B")
UK_df %>% MY_excess_return(., "UK_HY", "UK")
UK_df %>% mutate_at( MY_excess_return(., "UK_HY", "UK"), MY_excess_return(., "UK_HY_B", "UK_B"))
UK_df %>% mutate( MY_excess_return(., "UK_HY", "UK"), MY_excess_return(., "UK_HY_B", "UK_B"))
UK_df %>% mutate(E= MY_excess_return(., "UK_HY", "UK"))
UK_df %>% colnames
UK_df %>% MY_excess_return(., "UK_HY", "UK") %>% MY_excess_return("UK_HY_B", "UK_B")
UK_df %>% colnames
UK_df %>% MY_excess_return(., "UK_HY", "UK") %>% MY_excess_return(., "UK_HY_B", "UK_B")
UK_df %>% MY_excess_return(., "UK_HY", "UK")
UK_df %>% MY_excess_return(., "UK_HY_B", "UK_B")
A <- UK_df %>% MY_excess_return(., "UK_HY", "UK")
B <- UK_df %>% MY_excess_return(., "UK_HY_B", "UK_B")
UK <- left_join(A, B, date)
UK <- left_join(A, B, "date")
UK
US_df %>% colnames
EY_df %>% colnames
EU_df %>% colnames
JP_df %>% colnames
EM_df %>% colnames
SA_df %>% colnames
# loadings
pacman::p_load("xts", "tidyverse", "tbl2xts", "PerformanceAnalytics",
"lubridate", "glue")
original_df <- readxl::read_xlsx("data/MAD .xlsx")
#  change the column names for ease of analysis
geographical_codenames <- c("UK_HY", "EM_HY", "UK", "EM", "UK_HY_B", "UK_B", "JP_HY", "EU", "US_HY", "US", "W_HY", "W", "EU_DG", "EU_2", "JP_DG", "US_DG", "US_2", "JP", "SA_DG", "SA", "SA_HY", "EU_HY")
colnames(original_df)[2:23] <- geographical_codenames
#  lets get different regional data sets to analysze independently then later join
UK_df <- original_df %>% .[, grepl("UK|Date", colnames(.)) ]
US_df <- original_df %>% .[, grepl("US|Date", colnames(.)) ]
EU_df <- original_df %>% .[, grepl("EU|Date", colnames(.)) ]
EM_df <- original_df %>% .[, grepl("EM|Date", colnames(.)) ]
JP_df <- original_df %>% .[, grepl("JP|Date", colnames(.)) ]
SA_df <- original_df %>% .[, grepl("SA|Date", colnames(.)) ]
#  Lets start the analyses
source("code/simpleexcessreturn.R")
source("code/EXCESSRETURN.R")
library(glue)
#  just simple excess returns
A <- UK_df %>% MY_excess_return(., "UK_HY", "UK")
B <- UK_df %>% MY_excess_return(., "UK_HY_B", "UK_B")
UK <- left_join(A, B, "date")
A <- US_df %>% MY_excess_return(., "US_HY", "US")
B <- US_df %>% MY_excess_return(., "US_DG", "US_2")
US <- left_join(A, B, "date")
A <- EU_df %>% MY_excess_return(., "EU_HY", "EU")
B <- EU_df %>% MY_excess_return(., "EU_DG", "EU_2")
EU <- left_join(A, B, "date")
A <- JP_df %>% MY_excess_return(., "JP_HY", "JP")
B <- JP_df %>% MY_excess_return(., "JP_DG", "JP")
JP <- left_join(A, B, "date")
EM <- US_df %>% MY_excess_return(., "EM_HY", "EM")
source("code/simpleexcessreturn.R")
source("code/EXCESSRETURN.R")
library(glue)
#  just simple excess returns
A <- UK_df %>% MY_excess_return(., "UK_HY", "UK")
B <- UK_df %>% MY_excess_return(., "UK_HY_B", "UK_B")
UK <- left_join(A, B, "date")
A <- US_df %>% MY_excess_return(., "US_HY", "US")
B <- US_df %>% MY_excess_return(., "US_DG", "US_2")
US <- left_join(A, B, "date")
A <- EU_df %>% MY_excess_return(., "EU_HY", "EU")
B <- EU_df %>% MY_excess_return(., "EU_DG", "EU_2")
EU <- left_join(A, B, "date")
A <- JP_df %>% MY_excess_return(., "JP_HY", "JP")
B <- JP_df %>% MY_excess_return(., "JP_DG", "JP")
JP <- left_join(A, B, "date")
EM <- EM_df %>% MY_excess_return(., "EM_HY", "EM")
A <- SA_df %>% MY_excess_return(., "SA_HY", "SA")
B <- SA_df %>% MY_excess_return(., "SA_DG", "SA")
SA <- left_join(A, B, "date")
SA
EM
EU
US<- left_join(A, B, "date")
US
UK
