---
output:
  md_document:
    variant: markdown_github
---

# Ojective

these are systematic portfolios, is there some general signal that they all give. thats all we need to find out for our calcs. 

```{r}
rm(list = ls())
# loadings
library(PerformanceAnalytics)
library(tidyverse)
pacman::p_load("tidyr", "dplyr")
df<- readxl::read_xlsx("data/MAD Dividend index series.xlsx") %>% as.tibble()
```
# relative perfroance calcs

this section involves the wrangling needed to make analysis. so here we create the data for analysis.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# lets get monthly returns for each, annulizae then get the excess returns 
# for analysis 
index_starts <- df %>% gather(index, px, -Date) %>% 
  rename(date = Date) %>%
  mutate(YM = format(date, "%y %b")) %>% 
  group_by(index, YM) %>%
  arrange(date) %>% filter(date == first(date)) %>% filter(!is.na(px)) %>% group_by(index) %>% 
  filter(date == first(date)) %>% distinct(date)

# monthly returns 
rets <- df %>% gather(index, px, -Date) %>% 
  rename(date = Date)%>% filter(date <= ymd(20230101)) %>% 
  mutate(YM = format(date, "%y %b")) %>% 
  group_by(index, YM) %>%
  arrange(date) %>%
  filter(date == last(date))%>% 
  group_by(index) %>% 
  mutate(ret = px/lag(px)-1) %>%
  mutate(ret = coalesce(ret, 0)) %>% ungroup() %>% select(-YM, -px)

# execss returns and second moment function 
moments <- function(df, index_name, bm_name) {
  annulized.return <- df %>%
    mutate(Y = format(date, "%y")) %>%
    group_by(index) %>%
    summarise(
      date = last(date),
      N = n(),
      "Ann Return" = (prod(1 + ret))^(12 / N) - 1
    ) %>%
    select(-N)

  annulized_return <- annulized.return %>%
    filter(index %in% c(index_name, bm_name)) %>%
    pivot_wider(names_from = index, values_from = "Ann Return") %>%rename(ind = index_name, bm = bm_name) %>%
    mutate(excess_return = ind - bm) %>%
    select(date, excess_return)

  timeseries.ann.ret <- df %>%
    mutate(Y = format(date, "%y")) %>%
    group_by(index, Y) %>%
    summarise(
      date = last(date),
      N = n(),
      "Ann Return" = (prod(1 + ret))^(12 / N) - 1
    ) %>%
    ungroup() %>%
    select(-N, -Y)

  trackingerror <- timeseries.ann.ret %>%
    filter(index %in% c(index_name, bm_name)) %>%
    pivot_wider(names_from = index, values_from = "Ann Return") %>% rename(ind = index_name, bm = bm_name) %>%
    mutate(excess_return = ind - bm) %>%
    select(date, excess_return) %>%
    summarise(te = sd(excess_return))

  moments <- bind_cols(annulized_return, trackingerror) %>%
    mutate(Index = index_name)

}
# get excess returns
excess.returns.te <- bind_rows(moments(rets, "FUDP", "TUKXG"),
    moments(rets, "M2GBDY", "GDDUUK"),
       moments(rets, "M2WDHDVD...12", "GDDUWI"),
        moments(rets, "SPDAEET", "SPTR350E"),
        results <-  moments(rets, "SPDAUDT", "SPXT"),
          moments(rets, "SPJXDAJT", "TPXDDVD"),
             moments(rets, "SPSADAZT", "JALSH"),
             moments(rets, "TJDIVD", "JALSH"))

saveRDS(excess.returns.te, "data/moments.rds")

# cumulative return function 
cumulative_series <- function(df, index_name, bm_name){
  
  cumul <- df %>%
    filter(index %in% c(index_name, bm_name)) %>%
    pivot_wider(names_from = index, values_from = ret) %>%
    rename(ind = index_name, bm = bm_name) %>%
    mutate(excess_return = ind - bm) %>%
    select(date, excess_return) %>% 
    mutate(roi = cumprod(1 + excess_return)) %>%
    select(-excess_return) %>%
    rename(!!glue::glue("{index_name}_roi") := roi)
  
 cumul 
}
    a <- cumulative_series(rets, "FUDP", "TUKXG")
    b <- cumulative_series(rets, "M2GBDY", "GDDUUK")
    c <- cumulative_series(rets, "M2WDHDVD...12", "GDDUWI")
    d <- cumulative_series(rets, "SPDAEET", "SPTR350E")
    e <- cumulative_series(rets, "SPDAUDT", "SPXT")
    f <- cumulative_series(rets, "SPJXDAJT", "TPXDDVD")
    g <- cumulative_series(rets, "SPSADAZT", "JALSH")
    h <- cumulative_series(rets, "TJDIVD", "JALSH")

# convert to list then provide in a single df
cumulative_returns <- list(a, b, c, d, e, f, g, h) %>%
  reduce(inner_join, by = 'date') %>%
  gather(index, "Excess Cumu", -date) %>%
  mutate(index = str_remove(index, "_roi"))

saveRDS(cumulative_returns, "data/cumulative.rds")

# get excess

excess_series <- function(df, index_name, bm_name){
  
  cumul <- df %>%
    filter(index %in% c(index_name, bm_name)) %>%
    pivot_wider(names_from = index, values_from = ret) %>%
    rename(ind = {{index_name}}, bm = {{bm_name}}) %>%
    mutate(excess_return = ind - bm) %>%
    select(date, excess_return) %>% 
    rename(!!glue::glue("{index_name}" ):= excess_return)

  
  cumul 
}
# get the excess return df 

    a <- excess_series(rets, "FUDP", "TUKXG")
    b <- excess_series(rets, "M2GBDY", "GDDUUK")
    c <- excess_series(rets, "M2WDHDVD...12", "GDDUWI")
    d <- excess_series(rets, "SPDAEET", "SPTR350E")
    e <- excess_series(rets, "SPDAUDT", "SPXT")
    f <- excess_series(rets, "SPJXDAJT", "TPXDDVD")
    g <- excess_series(rets, "SPSADAZT", "JALSH")
    h <- excess_series(rets, "TJDIVD", "JALSH")

# convert to list then provide in a single df
excess_returns <- list(a, b, c, d, e, f, g, h) %>%
  reduce(inner_join, by = 'date') %>%
  gather(index, "Excess", -date)

name_mapping <- excess_returns %>%  mutate(
    Country = case_when(
      index == "FUDP" ~ "US",
      index == "M2GBDY" ~ "UK",
      index == "M2WDHDVD...12" ~ "UK",  
      index == "SPDAEET" ~ "EU",
      index == "SPDAUDT" ~ "UK",
      index == "SPJXDAJT" ~ "JP",
      index == "SPSADAZT" ~ "SA",
      index == "TJDIVD" ~ "SA"
    )
  , Signal = case_when(
      index == "FUDP" ~ "Dividend Yield",
      index == "M2GBDY" ~ "Dividend Yield",
      index == "M2WDHDVD...12" ~ "Dividend Yield",  
      index == "SPDAEET" ~ "Dividend Growth Per Share",
      index == "SPDAUDT" ~ "Dividend Yield",
      index == "SPJXDAJT" ~ "Dividend Yield",
      index == "SPSADAZT" ~ "Dividend Growth Per Share",
      index == "TJDIVD" ~ "Dividend Yield"
    )) %>% select(index, Country, Signal) %>% distinct()

cumulative_returns <- cumulative_returns %>% merge(., name_mapping, "index")

saveRDS(cumulative_returns, "data/cumulative.rds")
```

# Return Stratification

-   to get a more nuanced picture of the performance over time, but first
-   select dates from the top percentile is 95th and bottom is 5 percentile.

## Market volatility 

```{r echo=TRUE, message=FALSE, warning=FALSE}
#   get rolling volatility periods for the past 36 months, gives a wider range of analysis, make the data monthly. 
 vol_data <- readxl::read_xlsx("data/volatility for indexes.xlsx") %>% arrange(Date) %>% 
  gather(index, px , -Date) %>% rename(date = Date) %>% 
  mutate(YM = format(date, "%y %b")) %>% 
  group_by(YM, index) %>% filter(date == last(date)) %>% group_by(index) %>% 
  mutate(ret = px/lag(px)-1, RollSD = RcppRoll::roll_sd(1 + ret, 12, fill = NA, align = "right") * 
             sqrt(12)) %>% 
    filter(!is.na(RollSD))

vol_data_list <- vol_data %>% group_split(index)

# create and save dates in a list
hivol_stratification_dates <- list()

for (i in seq_along(vol_data_list)) {
  df <- vol_data_list[[i]] %>% as.tibble()
  
  vol_strat <- df %>%  
    mutate(topQ = quantile(RollSD, probs = 0.90), 
           botQ = quantile(RollSD, probs = 0.1),
           Strat = ifelse(RollSD >= topQ, "HiVol", 
                          ifelse(RollSD <= botQ, "LowVol", "Normal_Vol")))
  
  hivol_dates <- vol_strat %>% 
    filter(Strat %in% "HiVol") %>% 
    pull(date)
  
  hivol_stratification_dates[[i]] <- hivol_dates
}

# give names 
names(hivol_stratification_dates) <- c("hivol_per_vector_uk", "hivol_per_vector_sa", "hivol_per_vector_eu", "hivol_per_vector_us")

# repeat for low vol
lovol_stratification_dates <- list()

for (i in seq_along(vol_data_list)) {
  
  df <- vol_data_list[[i]] %>% as.tibble()
  
vol_strat <- df %>%  mutate(topQ = quantile(RollSD, probs = 0.95), 
               botQ = quantile(RollSD, probs = 0.05),
               Strat = ifelse(RollSD >= topQ, "HiVol", 
                           ifelse(RollSD <= botQ, "LowVol", "Normal_Vol")))
 lovol_dates <- vol_strat %>% filter(Strat %in% "LowVol") %>% pull(date)  

lovol_stratification_dates[[i]] <-  lovol_dates 
}

names(lovol_stratification_dates) <- c("lovol_per_vector_uk", "lovol_per_vector_sa", "lovol_per_vector_eu", "lovol_per_vector_us")

# get everything to environment 
list2env(hivol_stratification_dates, envir = .GlobalEnv)
list2env(lovol_stratification_dates, envir = .GlobalEnv)


# get stratified returns
stratifier <- function(raw_df, index_name, Date_vector, Description) {

  Mk_df <- raw_df %>%
    filter(date %in% Date_vector & index == index_name) %>%
    group_by(index) %>%
    summarize( "Cycle" = Description, Months = n(), "Ann Ret" = (prod(1+Excess)^(12/Months)-1) *100)

  Mk_df
}

# get the market cycle dfs  
High_vol_cycle_returns <- bind_rows (stratifier(excess_returns, "FUDP", hivol_per_vector_us, "High Vol" ),
  stratifier(excess_returns, "M2GBDY", hivol_per_vector_uk, "High Vol" ),
   stratifier(excess_returns, "M2WDHDVD...12", hivol_per_vector_uk, "High Vol" ), 
    stratifier(excess_returns, "SPDAEET", hivol_per_vector_eu, "High Vol" ), 
     stratifier(excess_returns, "SPDAUDT", hivol_per_vector_uk, "High Vol" ), 
      stratifier(excess_returns, "SPJXDAJT", hivol_per_vector_us, "High Vol" ), 
       stratifier(excess_returns, "SPSADAZT", hivol_per_vector_sa, "High Vol" ),
        stratifier(excess_returns, "TJDIVD", hivol_per_vector_sa, "High Vol" ))%>% merge(., name_mapping, "index")

saveRDS(High_vol_cycle_returns, "data/highvol.rds")
 
Lo_vol_cycle_returns <- bind_rows (stratifier(excess_returns, "FUDP", lovol_per_vector_us, "lo Vol" ),
  stratifier(excess_returns, "M2GBDY", lovol_per_vector_uk, "lo Vol" ),
   stratifier(excess_returns, "M2WDHDVD...12", lovol_per_vector_uk, "lo Vol" ), 
    stratifier(excess_returns, "SPDAEET", lovol_per_vector_eu, "lo Vol" ), 
     stratifier(excess_returns, "SPDAUDT", lovol_per_vector_uk, "lo Vol" ), 
      stratifier(excess_returns, "SPJXDAJT", lovol_per_vector_us, "lo Vol" ), 
       stratifier(excess_returns, "SPSADAZT", lovol_per_vector_sa, "lo Vol" ),
        stratifier(excess_returns, "TJDIVD", lovol_per_vector_sa, "lo Vol" ))%>% merge(., name_mapping, "index")

saveRDS(Lo_vol_cycle_returns, "data/lovol.rds")
```

## Interest Rate Volatility
```{r}
rate_data <- readxl::read_xlsx("data/Policy Rates.xlsx") 

names <- c("Date", "US", "UK", "JP", "ECB", "SA")

colnames(rate_data) <- names

US_rates <- rate_data %>% select(Date, US)
UK_rates <- rate_data %>% select(Date, UK)
JP_rates <- rate_data %>% select(Date, JP)
SA_rates <- rate_data %>% select(Date, SA)
ECB_rates <- rate_data %>% select(Date, ECB)
#  rename the columns for the function to work
source(file = "code/Interest_Regime.R")

Regime_df <- Regime_change_df(US_rates, "US", 5)
Hiking_date_vector_us <- Regime_df %>% filter(regime %in% "Hiking") %>% pull(Date)
Cutting_date_vector_us <- Regime_df %>% filter(regime %in% "Cutting") %>% pull(Date)
Neutral_date_vector_us <- Regime_df %>% filter(regime %in% "Neutral") %>% pull(Date) 

Regime_df <- Regime_change_df(UK_rates, "UK", 5)
Hiking_date_vector_uk <- Regime_df %>% filter(regime %in% "Hiking") %>% pull(Date)
Cutting_date_vector_uk <- Regime_df %>% filter(regime %in% "Cutting") %>% pull(Date)
Neutral_date_vector_uk <- Regime_df %>% filter(regime %in% "Neutral") %>% pull(Date) 

Regime_df <- Regime_change_df(JP_rates, "JP", 5)
Hiking_date_vector_jp <- Regime_df %>% filter(regime %in% "Hiking") %>% pull(Date)
Cutting_date_vector_jp <- Regime_df %>% filter(regime %in% "Cutting") %>% pull(Date)
Neutral_date_vector_jp <- Regime_df %>% filter(regime %in% "Neutral") %>% pull(Date) 

Regime_df <- Regime_change_df(SA_rates, "SA", 5)
Hiking_date_vector_sa <- Regime_df %>% filter(regime %in% "Hiking") %>% pull(Date)
Cutting_date_vector_sa <- Regime_df %>% filter(regime %in% "Cutting") %>% pull(Date)
Neutral_date_vector_sa <- Regime_df %>% filter(regime %in% "Neutral") %>% pull(Date) 

Regime_df <- Regime_change_df(ECB_rates, "ECB", 5)
Hiking_date_vector_eu <- Regime_df %>% filter(regime %in% "Hiking") %>% pull(Date)
Cutting_date_vector_eu <- Regime_df %>% filter(regime %in% "Cutting") %>% pull(Date)
Neutral_date_vector_eu <- Regime_df %>% filter(regime %in% "Neutral") %>% pull(Date) 

# Hiking Performance

Hiking_cycle_returns <- bind_rows (stratifier(excess_returns, "FUDP", Hiking_date_vector_uk, "Hiking" ),
  stratifier(excess_returns, "M2GBDY", Hiking_date_vector_uk , "Hiking" ),
   stratifier(excess_returns, "M2WDHDVD...12", Hiking_date_vector_uk , "Hiking" ), 
    stratifier(excess_returns, "SPDAEET", Hiking_date_vector_eu, "Hiking" ), 
     stratifier(excess_returns, "SPDAUDT", Hiking_date_vector_uk , "Hiking" ), 
      stratifier(excess_returns, "SPJXDAJT", Hiking_date_vector_us, "Hiking" ), 
       stratifier(excess_returns, "SPSADAZT", Hiking_date_vector_sa, "Hiking"),
        stratifier(excess_returns, "TJDIVD", Hiking_date_vector_sa, "Hiking")) %>% merge(., name_mapping, "index")
 
saveRDS(Hiking_cycle_returns, "data/hikingcycle.rds")

Cutting_cycle_returns <- bind_rows (stratifier(excess_returns, "FUDP", hivol_per_vector_us, "Cutting" ),
  stratifier(excess_returns, "M2GBDY", Cutting_date_vector_uk , "Cutting" ),
   stratifier(excess_returns, "M2WDHDVD...12", Cutting_date_vector_uk , "Cutting" ), 
    stratifier(excess_returns, "SPDAEET", Cutting_date_vector_eu, "Cutting" ), 
     stratifier(excess_returns, "SPDAUDT", Cutting_date_vector_uk , "Cutting" ), 
      stratifier(excess_returns, "SPJXDAJT", Cutting_date_vector_us, "Cutting" ), 
       stratifier(excess_returns, "SPSADAZT", Cutting_date_vector_sa, "Cutting"),
        stratifier(excess_returns, "TJDIVD", Cutting_date_vector_sa, "Cutting")) %>% merge(., name_mapping, "index")

saveRDS(Cutting_cycle_returns, "data/cuttingcycle.rds")

```

# Structure of the analysis in the write up 



